@startuml output_heads

package output_heads {
    package output_head {
        abstract class OutputHead {
            + hparams: OutputHead.HParams
            {abstract} + forward(observations: Observations representations: Tensor): Actions
            {abstract} + get_loss(ForwardPass, Actions, Rewards) -> Loss
        }
        abstract class OutputHead.HParams {
            + {static} available_activations: ClassVar[Dict[str, Type[nn.Module]]]
            + hidden_layers: int
            + hidden_neurons: List[int]
            + activation: Type[nn.Module] = "tanh"
        }
        OutputHead *-- Actions : outputs
        OutputHead *-- OutputHead.HParams
    }

    BaseModel "1" *-- "1" OutputHead
    package classification {
        class ClassificationHead implements OutputHead {
            + forward(Observations representations: Tensor): ClassificationHeadOutput
            + get_loss(ForwardPass, ClassificationOutput, Rewards): Loss
        }
        class ClassificationHead.HParams extends OutputHead.HParams {}
        class ClassificationHeadOutput extends Actions {
            + y_pred: Tensor
            + logits: Tensor
        }
        ClassificationHead *-- ClassificationHeadOutput : outputs
        ClassificationHead *-- ClassificationHead.HParams

    }
    package regression {
        class RegressionHead implements OutputHead {}
    }

    package rl {
        package policy_head {
            class PolicyHead extends ClassificationHead {
                + forward(observations: Observations representations: Tensor): PolicyHeadOutput
                + hparams: PolicyHead.HParams
            }
            class PolicyHead.HParams extends ClassificationHead.HParams {
                + forward(observations: Observations representations: Tensor): PolicyHeadOutput
            }
            class PolicyHeadOutput extends ClassificationHeadOutput {
                action_dist: Distribution
            }
            PolicyHead *-- PolicyHeadOutput : outputs
            PolicyHead *-- PolicyHead.HParams

        }
        package episodic_a2c {
            class EpisodicA2C extends PolicyHead {
                + actor: nn.Module
                + critic: nn.Module
                + get_episode_loss(Observations, Actions, Rewards, done: bool): Loss
            }
            class EpisodicA2C.HParams extends PolicyHead.HParams {
                + normalize_advantages: bool = False
                + actor_loss_coef: float = 0.5
                + critic_loss_coef: float = 0.5
                + entropy_loss_coef: float = 0.1
                + max_policy_grad_norm: Optional[float] = None
                + gamma: float = 0.99
                + learning_rate: float = 1e-2
            }
            class A2CHeadOutput extends PolicyHeadOutput{
                + value: Tensor
            }
            EpisodicA2C *-- A2CHeadOutput : outputs
            EpisodicA2C *-- EpisodicA2C.HParams
        }
        package actor_critic_head {
            class ActorCriticHead extends ClassificationHead {
                + hparams: ActorCriticHead.HParams
                + actor: nn.Module
                + critic: nn.Module 
            }
            class ActorCriticHead.HParams extends ClassificationHead.HParams {
                + gamma: float = 0.95
                + learning_rate: float = 1e-3
            }
            ActorCriticHead *-- ActorCriticHead.HParams
        }
    ' remove PolicyHeadOutput
    ' remove A2CHeadOutput
    }
    
}

@enduml